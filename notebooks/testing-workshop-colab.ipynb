{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sparrow0hawk/lesson-gpu-programming/blob/gh-pages/notebooks/testing-workshop-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7030baf3-3237-4c06-9633-1d1d3663e9df",
      "metadata": {
        "id": "7030baf3-3237-4c06-9633-1d1d3663e9df"
      },
      "source": [
        "# Testing workshop for Bede"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "812b0eb8-e90e-4394-b299-770ba65c2af3",
      "metadata": {
        "id": "812b0eb8-e90e-4394-b299-770ba65c2af3"
      },
      "outputs": [],
      "source": [
        "! echo $HOSTNAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "842bdb86-1f5d-46c8-9a3e-9862ae00e74b",
      "metadata": {
        "id": "842bdb86-1f5d-46c8-9a3e-9862ae00e74b"
      },
      "outputs": [],
      "source": [
        "! arch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dPESDZxkSDs7"
      },
      "id": "dPESDZxkSDs7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3419cf7-6add-427a-a2a8-4f879b538918",
      "metadata": {
        "id": "c3419cf7-6add-427a-a2a8-4f879b538918"
      },
      "outputs": [],
      "source": [
        "! date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac100202-2251-46b7-be8b-ce22da8adfed",
      "metadata": {
        "id": "ac100202-2251-46b7-be8b-ce22da8adfed"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "size = 4096 * 4096\n",
        "input = np.random.random(size).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54408328-2742-4450-9d9c-04770031e3d1",
      "metadata": {
        "id": "54408328-2742-4450-9d9c-04770031e3d1"
      },
      "outputs": [],
      "source": [
        "%timeit -n 1 -r 1 output = np.sort(input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8578175-6857-41b5-bc19-1fa4820ab948",
      "metadata": {
        "id": "c8578175-6857-41b5-bc19-1fa4820ab948"
      },
      "outputs": [],
      "source": [
        "from cupyx.profiler import benchmark\n",
        "import cupy as cp\n",
        "input_gpu = cp.asarray(input)\n",
        "execution_gpu = benchmark(cp.sort, (input_gpu,), n_repeat=10)\n",
        "gpu_avg_time = np.average(execution_gpu.gpu_times)\n",
        "print(f\"{gpu_avg_time:.6f} s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc49b0a4-1ad6-4aab-880a-6c620474e35b",
      "metadata": {
        "id": "fc49b0a4-1ad6-4aab-880a-6c620474e35b"
      },
      "outputs": [],
      "source": [
        "speedup = 1.83 / 0.008949\n",
        "print(speedup)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "064d3d16-a840-4ed1-b51c-fdb600398a2f",
      "metadata": {
        "id": "064d3d16-a840-4ed1-b51c-fdb600398a2f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Construct an image with repeated delta functions\n",
        "deltas = np.zeros((2048, 2048))\n",
        "deltas[8::16,8::16] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5729701f-9887-4a76-8dca-141d603f7d3f",
      "metadata": {
        "id": "5729701f-9887-4a76-8dca-141d603f7d3f"
      },
      "outputs": [],
      "source": [
        "import pylab as pyl\n",
        "# Necessary command to render a matplotlib image in a Jupyter notebook.\n",
        "%matplotlib inline\n",
        "\n",
        "# Display the image\n",
        "# You can zoom in using the menu in the window that will appear\n",
        "pyl.imshow(deltas[0:32, 0:32])\n",
        "pyl.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00d33c38-c6e1-427e-b1b6-95904599f140",
      "metadata": {
        "id": "00d33c38-c6e1-427e-b1b6-95904599f140"
      },
      "outputs": [],
      "source": [
        "x, y = np.meshgrid(np.linspace(-2, 2, 15), np.linspace(-2, 2, 15))\n",
        "dst = np.sqrt(x*x + y*y)\n",
        "sigma = 1\n",
        "muu = 0.000\n",
        "gauss = np.exp(-((dst-muu)**2/(2.0 * sigma**2)))\n",
        "pyl.imshow(gauss)\n",
        "pyl.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f1d7100-3755-4d8c-aa3e-5fec3a6d15d7",
      "metadata": {
        "id": "2f1d7100-3755-4d8c-aa3e-5fec3a6d15d7"
      },
      "outputs": [],
      "source": [
        "from scipy.signal import convolve2d as convolve2d_cpu\n",
        "\n",
        "convolved_image_using_CPU = convolve2d_cpu(deltas, gauss)\n",
        "pyl.imshow(convolved_image_using_CPU[0:32, 0:32])\n",
        "pyl.show()\n",
        "%timeit -n 1 -r 1 convolve2d_cpu(deltas, gauss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9558803b-b486-491d-80b9-b89cfa1fffcb",
      "metadata": {
        "id": "9558803b-b486-491d-80b9-b89cfa1fffcb"
      },
      "outputs": [],
      "source": [
        "import cupy as cp\n",
        "\n",
        "deltas_gpu = cp.asarray(deltas)\n",
        "gauss_gpu = cp.asarray(gauss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4a7fe09-cc6b-4fa5-ae20-3596809103db",
      "metadata": {
        "id": "e4a7fe09-cc6b-4fa5-ae20-3596809103db"
      },
      "outputs": [],
      "source": [
        "from cupyx.scipy.signal import convolve2d as convolve2d_gpu\n",
        "\n",
        "convolved_image_using_GPU = convolve2d_gpu(deltas_gpu, gauss_gpu)\n",
        "%timeit -n 7 -r 1 convolved_image_using_GPU = convolve2d_gpu(deltas_gpu, gauss_gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "316bb087-9e4a-4d9a-aa94-f048cd5e3ad5",
      "metadata": {
        "id": "316bb087-9e4a-4d9a-aa94-f048cd5e3ad5"
      },
      "outputs": [],
      "source": [
        "from cupyx.profiler import benchmark\n",
        "\n",
        "execution_gpu = benchmark(convolve2d_gpu, (deltas_gpu, gauss_gpu), n_repeat=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3e550bf-fac7-4601-985d-4a0bcad4a9e9",
      "metadata": {
        "id": "c3e550bf-fac7-4601-985d-4a0bcad4a9e9"
      },
      "outputs": [],
      "source": [
        "gpu_avg_time = np.average(execution_gpu.gpu_times)\n",
        "print(f\"{gpu_avg_time:.6f} s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24cb3126-a4a5-4e95-a893-0a27be06b17f",
      "metadata": {
        "id": "24cb3126-a4a5-4e95-a893-0a27be06b17f"
      },
      "outputs": [],
      "source": [
        "np.allclose(convolved_image_using_GPU, convolved_image_using_CPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e1fc7d1-3be4-4607-bb7b-9f30b4a4097d",
      "metadata": {
        "id": "8e1fc7d1-3be4-4607-bb7b-9f30b4a4097d"
      },
      "outputs": [],
      "source": [
        "# this line should error\n",
        "# TypeError: Implicit conversion to a NumPy array is not allowed. Please use `.get()` to construct a NumPy array explicitly.\n",
        "convolve2d_cpu(deltas_gpu, gauss_gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15702ec9-ad54-4cb7-9265-488232f063ea",
      "metadata": {
        "id": "15702ec9-ad54-4cb7-9265-488232f063ea"
      },
      "outputs": [],
      "source": [
        "deltas_1d = deltas.ravel()\n",
        "gauss_1d = gauss.diagonal()\n",
        "%timeit -n 1 -r 1 np.convolve(deltas_1d, gauss_1d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f6c0851-caae-4ecc-b8ef-30074e549cb5",
      "metadata": {
        "id": "5f6c0851-caae-4ecc-b8ef-30074e549cb5"
      },
      "outputs": [],
      "source": [
        "deltas_1d_gpu = cp.asarray(deltas_1d)\n",
        "gauss_1d_gpu = cp.asarray(gauss_1d)\n",
        "\n",
        "execution_gpu = benchmark(np.convolve, (deltas_1d_gpu, gauss_1d_gpu), n_repeat=10)\n",
        "gpu_avg_time = np.average(execution_gpu.gpu_times)\n",
        "print(f\"{gpu_avg_time:.6f} s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "490b3402-ffdf-4836-9132-5d3c31243a41",
      "metadata": {
        "id": "490b3402-ffdf-4836-9132-5d3c31243a41"
      },
      "source": [
        "## Real world astropy example"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash \n",
        "\n",
        "mkdir data\n",
        "\n",
        "curl -L https://github.com/carpentries-incubator/lesson-gpu-programming/blob/gh-pages/data/GMRT_image_of_Galactic_Center.fits?raw=true -o data/GMRT_image_of_Galactic_Center.fits"
      ],
      "metadata": {
        "id": "Y4LQz8EsS6aR"
      },
      "id": "Y4LQz8EsS6aR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b4b4e59-56c3-4647-9544-956e01609aa1",
      "metadata": {
        "id": "7b4b4e59-56c3-4647-9544-956e01609aa1"
      },
      "outputs": [],
      "source": [
        "from astropy.io import fits\n",
        "\n",
        "with fits.open(\"data/GMRT_image_of_Galactic_Center.fits\") as hdul:\n",
        "    data = hdul[0].data.byteswap().newbyteorder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48d62d16-5a19-4e81-987b-cbff2502d8fa",
      "metadata": {
        "id": "48d62d16-5a19-4e81-987b-cbff2502d8fa"
      },
      "outputs": [],
      "source": [
        "from matplotlib.colors import LogNorm\n",
        "\n",
        "maxim = data.max()\n",
        "\n",
        "pyl.matshow(data, cmap=pyl.cm.gray_r, norm=LogNorm(vmin = maxim/100, vmax=maxim))\n",
        "pyl.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4e1915a-2caf-48c8-9f21-b64ae15bc357",
      "metadata": {
        "id": "e4e1915a-2caf-48c8-9f21-b64ae15bc357"
      },
      "outputs": [],
      "source": [
        "subimage = data[500:1000, 500:1000]\n",
        "maxim_sub = subimage.max()\n",
        "pyl.matshow(subimage, cmap=pyl.cm.gray_r, \\\n",
        "            norm=LogNorm(vmin = maxim_sub/100, vmax=maxim_sub))\n",
        "pyl.colorbar()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab2e6ece-af86-4d07-9686-959edf68d130",
      "metadata": {
        "id": "ab2e6ece-af86-4d07-9686-959edf68d130"
      },
      "outputs": [],
      "source": [
        "mean_ = data.mean()\n",
        "median_ = np.median(data)\n",
        "stddev_ = np.std(data)\n",
        "max_ = np.amax(data)\n",
        "print(f\"mean = {mean_:.3e}, median = {median_:.3e}, sttdev = {stddev_:.3e},\\\n",
        "maximum = {max_:.3e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d0e6ff8-a9b6-4eb0-b481-a3288e503075",
      "metadata": {
        "id": "2d0e6ff8-a9b6-4eb0-b481-a3288e503075"
      },
      "outputs": [],
      "source": [
        "# Flattening our 2D data first makes subsequent steps easier.\n",
        "data_flat = data.ravel()\n",
        "# Here is a kappa, sigma clipper for the CPU\n",
        "def kappa_sigma_clipper(data_flat):\n",
        "    while True:\n",
        "         med = np.median(data_flat)\n",
        "         std = np.std(data_flat)\n",
        "         clipped_lower = data_flat.compress(data_flat > med - 3 * std)\n",
        "         clipped_both = clipped_lower.compress(clipped_lower < med + 3 * std)\n",
        "         if len(clipped_both) == len(data_flat):\n",
        "             break\n",
        "         data_flat = clipped_both  \n",
        "    return data_flat\n",
        "\n",
        "data_clipped = kappa_sigma_clipper(data_flat)\n",
        "timing_ks_clipping_cpu = %timeit -o kappa_sigma_clipper(data_flat)\n",
        "fastest_ks_clipping_cpu = timing_ks_clipping_cpu.best\n",
        "print(f\"Fastest CPU ks clipping time = {1000 * fastest_ks_clipping_cpu:.3e} ms.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cda73fb-78e4-4588-80f5-410c4e127000",
      "metadata": {
        "id": "7cda73fb-78e4-4588-80f5-410c4e127000"
      },
      "outputs": [],
      "source": [
        "mean_ = data_clipped.mean()\n",
        "median_ = np.median(data_clipped)\n",
        "stddev_ = np.std(data_clipped)\n",
        "max_ = np.amax(data_clipped)\n",
        "print(f\"mean = {mean_:.3e}, median = {median_:.3e}, sttdev = {stddev_:.3e},\\\n",
        "maximum = {max_:.3e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a13e9f85-eebd-4b30-83fd-056845bbb2d6",
      "metadata": {
        "id": "a13e9f85-eebd-4b30-83fd-056845bbb2d6"
      },
      "outputs": [],
      "source": [
        "data_flat_gpu = cp.asarray(data_flat)\n",
        "data_gpu_clipped = kappa_sigma_clipper(data_flat_gpu)\n",
        "timing_ks_clipping_gpu = benchmark(kappa_sigma_clipper, (data_flat_gpu.ravel(), ), n_repeat=10)\n",
        "fastest_ks_clipping_gpu = np.min(timing_ks_clipping_gpu.gpu_times)\n",
        "print(f\"{1000 * fastest_ks_clipping_gpu:.3e} ms\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d32b0060-b957-432a-98d1-5a23724c5dcd",
      "metadata": {
        "id": "d32b0060-b957-432a-98d1-5a23724c5dcd"
      },
      "outputs": [],
      "source": [
        "stddev_gpu_ = np.std(data_gpu_clipped)\n",
        "print(f\"standard deviation of background_noise = {stddev_:.4f} Jy/beam\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad3c7504-9218-469b-9d0e-3f4db3302ccd",
      "metadata": {
        "id": "ad3c7504-9218-469b-9d0e-3f4db3302ccd"
      },
      "outputs": [],
      "source": [
        "threshold = 5 * stddev_\n",
        "segmented_image = np.where(data > threshold, 1,  0)\n",
        "timing_segmentation_CPU = %timeit -o np.where(data > threshold, 1,  0)\n",
        "fastest_segmentation_CPU = timing_segmentation_CPU.best \n",
        "print(f\"Fastest CPU segmentation time = {1000 * fastest_segmentation_CPU:.3e} ms.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cdf3980-c290-4bf7-aad2-b6ec9f6a54c9",
      "metadata": {
        "id": "7cdf3980-c290-4bf7-aad2-b6ec9f6a54c9"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import label\n",
        "labelled_image = np.empty(data.shape)\n",
        "number_of_sources_in_image = label(segmented_image, output = labelled_image)\n",
        "sigma_unicode = \"\\u03C3\"\n",
        "print(f\"The number of sources in the image at the 5{sigma_unicode} level is \\\n",
        "{number_of_sources_in_image}.\")\n",
        "\n",
        "timing_CCL_CPU = %timeit -o label(segmented_image, output = labelled_image)\n",
        "fastest_CCL_CPU = timing_CCL_CPU.best\n",
        "print(f\"Fastest CPU CCL time = {1000 * fastest_CCL_CPU:.3e} ms.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1d2280b-5e56-4c8b-a020-45180f8592ad",
      "metadata": {
        "id": "d1d2280b-5e56-4c8b-a020-45180f8592ad"
      },
      "outputs": [],
      "source": [
        "print(f\"These are all the pixel values we can find in the labelled image: \\\n",
        "{np.unique(labelled_image)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9811034b-3cad-46fc-90f4-25575a376f26",
      "metadata": {
        "id": "9811034b-3cad-46fc-90f4-25575a376f26"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import center_of_mass, sum_labels\n",
        "all_positions = center_of_mass(data, labelled_image, \\\n",
        "                               range(1, number_of_sources_in_image+1))\n",
        "all_integrated_fluxes = sum_labels(data, labelled_image, \\\n",
        "                               range(1, number_of_sources_in_image+1))\n",
        "\n",
        "print (f'These are the ten highest integrated fluxes of the sources in my image: \\\n",
        "{np.sort(all_integrated_fluxes)[-10:]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ba268a4-3943-4c0a-ac6b-fa67aa220378",
      "metadata": {
        "id": "3ba268a4-3943-4c0a-ac6b-fa67aa220378"
      },
      "outputs": [],
      "source": [
        "%%timeit -o\n",
        "all_positions = center_of_mass(data, labelled_image, \\\n",
        "                               range(1, number_of_sources_in_image+1))\n",
        "all_integrated_fluxes = sum_labels(data, labelled_image, \\\n",
        "                               range(1, number_of_sources_in_image+1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04bde2ff-8950-49d6-873b-cc48dc827b2a",
      "metadata": {
        "id": "04bde2ff-8950-49d6-873b-cc48dc827b2a"
      },
      "outputs": [],
      "source": [
        "timing_source_measurements_CPU = _\n",
        "fastest_source_measurements_CPU = timing_source_measurements_CPU.best\n",
        "print(f\"Fastest CPU set of source measurements = \\\n",
        "{1000 * fastest_source_measurements_CPU:.3e} ms.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac28fc94-3c5e-47fb-a424-9280bb4427e8",
      "metadata": {
        "id": "ac28fc94-3c5e-47fb-a424-9280bb4427e8"
      },
      "outputs": [],
      "source": [
        "labelled_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6514a83-7fd0-4e91-921e-77fbba4287ee",
      "metadata": {
        "id": "f6514a83-7fd0-4e91-921e-77fbba4287ee"
      },
      "outputs": [],
      "source": [
        "data_gpu = cp.asarray(data)\n",
        "labelled_image_gpu = cp.asarray(labelled_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fed2359-ca0b-41df-8f3e-9409660849de",
      "metadata": {
        "id": "1fed2359-ca0b-41df-8f3e-9409660849de"
      },
      "outputs": [],
      "source": [
        "# Now on the GPU\n",
        "from cupyx.scipy.ndimage import center_of_mass as com_gpu\n",
        "from cupyx.scipy.ndimage import sum_labels as sl_gpu\n",
        "\n",
        "timing_position_measurements_GPU = benchmark(com_gpu, (data_gpu, labelled_image_gpu, \\\n",
        "                                      cp.arange(1, number_of_sources_in_image+1)),\n",
        "                                      n_repeat =10)\n",
        "fastest_position_measurements_GPU = np.amin(timing_position_measurements_GPU.gpu_times)\n",
        "timing_flux_measurements_GPU = benchmark(sl_gpu, (data_gpu, labelled_image_gpu, \\\n",
        "                                      cp.arange(1, number_of_sources_in_image+1)),\n",
        "                                      n_repeat =10)\n",
        "fastest_flux_measurements_GPU = np.amin(timing_flux_measurements_GPU.gpu_times)\n",
        "fastest_source_measurements_GPU = fastest_position_measurements_GPU + \\\n",
        "                                  fastest_flux_measurements_GPU\n",
        "print(f\"Fastest source measurements on the GPU take \\\n",
        " {1000 * fastest_source_measurements_GPU:.3e} ms\")\n",
        "print()\n",
        "speedup_factor = fastest_source_measurements_CPU/fastest_source_measurements_GPU\n",
        "print(f\"The speedup factor for source measurements is: {speedup_factor:.3e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f45c6c8-64c1-4f87-a949-7815ea5ac208",
      "metadata": {
        "id": "2f45c6c8-64c1-4f87-a949-7815ea5ac208"
      },
      "source": [
        "## Accelerate your Python code with Numba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42c30848-1f5c-4e39-884c-4da6d817e761",
      "metadata": {
        "id": "42c30848-1f5c-4e39-884c-4da6d817e761"
      },
      "outputs": [],
      "source": [
        "def find_all_primes_cpu(upper):\n",
        "    all_prime_numbers = []\n",
        "    for num in range(0, upper):\n",
        "        prime = True\n",
        "        for i in range(2, (num // 2) + 1):\n",
        "            if (num % i) == 0:\n",
        "                prime = False\n",
        "                break\n",
        "        if prime:\n",
        "            all_prime_numbers.append(num)\n",
        "    return all_prime_numbers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cc9ec06-9673-42a2-87d6-e010dd74592d",
      "metadata": {
        "id": "8cc9ec06-9673-42a2-87d6-e010dd74592d"
      },
      "outputs": [],
      "source": [
        "%timeit -n 10 -r 1 find_all_primes_cpu(10_000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff7ee3cc-3193-49b6-a246-a1c5cc033c98",
      "metadata": {
        "id": "ff7ee3cc-3193-49b6-a246-a1c5cc033c98"
      },
      "outputs": [],
      "source": [
        "from numba import jit\n",
        "\n",
        "@jit(nopython=True)\n",
        "def find_all_primes_cpu(upper):\n",
        "    all_prime_numbers = []\n",
        "    for num in range(0, upper):\n",
        "        prime = True\n",
        "        for i in range(2, (num // 2) + 1):\n",
        "            if (num % i) == 0:\n",
        "                prime = False\n",
        "                break\n",
        "        if prime:\n",
        "            all_prime_numbers.append(num)\n",
        "    return all_prime_numbers\n",
        "\n",
        "%timeit -n 10 -r 1 find_all_primes_cpu(10_000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f9c4ba7-9f21-46a6-ab2d-f4c1d79ea026",
      "metadata": {
        "id": "0f9c4ba7-9f21-46a6-ab2d-f4c1d79ea026"
      },
      "outputs": [],
      "source": [
        "# this cell should error\n",
        "# as its a repeat/alternate way to do the above\n",
        "\n",
        "from numba import jit\n",
        "\n",
        "upper = 10_000\n",
        "%timeit -n 10 -r 1 jit(nopython=True)(find_all_primes_cpu)(upper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af6f794e-c386-4663-a0c0-86be4e35d4f9",
      "metadata": {
        "id": "af6f794e-c386-4663-a0c0-86be4e35d4f9"
      },
      "outputs": [],
      "source": [
        "from numba import cuda\n",
        "\n",
        "@cuda.jit\n",
        "def check_prime_gpu_kernel(num, result):\n",
        "   result[0] =  num\n",
        "   for i in range(2, (num // 2) + 1):\n",
        "       if (num % i) == 0:\n",
        "           result[0] = 0\n",
        "           break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "734552b5-b275-4d3e-84c4-f02fcf7caf0d",
      "metadata": {
        "id": "734552b5-b275-4d3e-84c4-f02fcf7caf0d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "result = np.zeros((1), np.int32)\n",
        "check_prime_gpu_kernel[1, 1](11, result)\n",
        "print(result[0])\n",
        "check_prime_gpu_kernel[1, 1](12, result)\n",
        "print(result[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c42a5c99-3132-470b-bcbd-f38a1329847e",
      "metadata": {
        "id": "c42a5c99-3132-470b-bcbd-f38a1329847e"
      },
      "outputs": [],
      "source": [
        "numbers = np.arange(0, 10_000, dtype=np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fff0cc66-be02-4980-bb22-083540798098",
      "metadata": {
        "id": "fff0cc66-be02-4980-bb22-083540798098"
      },
      "outputs": [],
      "source": [
        "import numba as nb\n",
        "\n",
        "@nb.vectorize(['int32(int32)'], target='cuda')\n",
        "def check_prime_gpu(num):\n",
        "    for i in range(2, (num // 2) + 1):\n",
        "       if (num % i) == 0:\n",
        "           return 0\n",
        "    return num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1854a6ca-d2fe-4190-8594-5be319bdbd60",
      "metadata": {
        "id": "1854a6ca-d2fe-4190-8594-5be319bdbd60"
      },
      "outputs": [],
      "source": [
        "%timeit -n 10 -r 1 check_prime_gpu(numbers)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c824473-c405-4505-b636-82df55fa10e7",
      "metadata": {
        "id": "7c824473-c405-4505-b636-82df55fa10e7"
      },
      "source": [
        "## A Better Look at the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e12a5499-8005-47c7-957a-1d83244ae237",
      "metadata": {
        "id": "e12a5499-8005-47c7-957a-1d83244ae237"
      },
      "outputs": [],
      "source": [
        "import numba as nb\n",
        "\n",
        "@nb.vectorize(['int32(int32)'], target='cuda')\n",
        "def check_prime_gpu(num):\n",
        "    for i in range(2, (num // 2) + 1):\n",
        "       if (num % i) == 0:\n",
        "           return 0\n",
        "    return num\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51f3df27-f951-4726-a8f2-e240043a36dd",
      "metadata": {
        "id": "51f3df27-f951-4726-a8f2-e240043a36dd"
      },
      "outputs": [],
      "source": [
        "check_prime_gpu(np.arange(0, 10_000, dtype=np.int32))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98ee2d1c-2a99-42ba-b4af-f3e9dbef981f",
      "metadata": {
        "id": "98ee2d1c-2a99-42ba-b4af-f3e9dbef981f"
      },
      "source": [
        "## Your First GPU Kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca6ae53c-1e60-4930-bc11-55faccfcfca3",
      "metadata": {
        "id": "ca6ae53c-1e60-4930-bc11-55faccfcfca3"
      },
      "outputs": [],
      "source": [
        "def vector_add(A, B, C, size):\n",
        "    for item in range(0, size):\n",
        "        C[item] = A[item] + B[item]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f10bd050-d70b-4bef-b75a-02c7d58681d7",
      "metadata": {
        "id": "f10bd050-d70b-4bef-b75a-02c7d58681d7"
      },
      "outputs": [],
      "source": [
        "import cupy\n",
        "\n",
        "# size of the vectors\n",
        "size = 1024\n",
        "\n",
        "# allocating and populating the vectors\n",
        "a_gpu = cupy.random.rand(size, dtype=cupy.float32)\n",
        "b_gpu = cupy.random.rand(size, dtype=cupy.float32)\n",
        "c_gpu = cupy.zeros(size, dtype=cupy.float32)\n",
        "\n",
        "# CUDA vector_add\n",
        "vector_add_cuda_code = r'''\n",
        "extern \"C\"\n",
        "__global__ void vector_add(const float * A, const float * B, float * C, const int size)\n",
        "{\n",
        "    int item = threadIdx.x;\n",
        "    C[item] = A[item] + B[item];\n",
        "}\n",
        "'''\n",
        "vector_add_gpu = cupy.RawKernel(vector_add_cuda_code, \"vector_add\")\n",
        "\n",
        "vector_add_gpu((1, 1, 1), (size, 1, 1), (a_gpu, b_gpu, c_gpu, size))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16feea04-d181-47b3-919c-e37a95dbc4c8",
      "metadata": {
        "id": "16feea04-d181-47b3-919c-e37a95dbc4c8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "a_cpu = cupy.asnumpy(a_gpu)\n",
        "b_cpu = cupy.asnumpy(b_gpu)\n",
        "c_cpu = np.zeros(size, dtype=np.float32)\n",
        "\n",
        "vector_add(a_cpu, b_cpu, c_cpu, size)\n",
        "\n",
        "# test\n",
        "if np.allclose(c_cpu, c_gpu):\n",
        "    print(\"Correct results!\")\n",
        "else:\n",
        "    print(\"Wrong results!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e039d6a3-2782-44b8-835d-128c7f7ea23c",
      "metadata": {
        "id": "e039d6a3-2782-44b8-835d-128c7f7ea23c"
      },
      "outputs": [],
      "source": [
        "# this cell should error\n",
        "# can't do 2048 threads in a block\n",
        "# size of the vectors\n",
        "size = 2048\n",
        "\n",
        "# allocating and populating the vectors\n",
        "a_gpu = cupy.random.rand(size, dtype=cupy.float32)\n",
        "b_gpu = cupy.random.rand(size, dtype=cupy.float32)\n",
        "c_gpu = cupy.zeros(size, dtype=cupy.float32)\n",
        "\n",
        "# CUDA vector_add\n",
        "vector_add_gpu = cupy.RawKernel(r'''\n",
        "extern \"C\"\n",
        "__global__ void vector_add(const float * A, const float * B, float * C, const int size)\n",
        "{\n",
        "    int item = threadIdx.x;\n",
        "    C[item] = A[item] + B[item];\n",
        "}\n",
        "''', \"vector_add\")\n",
        "\n",
        "vector_add_gpu((1, 1, 1), (size, 1, 1), (a_gpu, b_gpu, c_gpu, size))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51fe6a30-652f-44c3-847e-bb8e81c3e70e",
      "metadata": {
        "id": "51fe6a30-652f-44c3-847e-bb8e81c3e70e"
      },
      "outputs": [],
      "source": [
        "# size of the vectors\n",
        "size = 2048\n",
        "\n",
        "# allocating and populating the vectors\n",
        "a_gpu = cupy.random.rand(size, dtype=cupy.float32)\n",
        "b_gpu = cupy.random.rand(size, dtype=cupy.float32)\n",
        "c_gpu = cupy.zeros(size, dtype=cupy.float32)\n",
        "\n",
        "# CUDA vector_add\n",
        "vector_add_gpu = cupy.RawKernel(r'''\n",
        "extern \"C\"\n",
        "__global__ void vector_add(const float * A, const float * B, float * C, const int size)\n",
        "{\n",
        "    int item = threadIdx.x;\n",
        "    C[item] = A[item] + B[item];\n",
        "}\n",
        "''', \"vector_add\")\n",
        "\n",
        "vector_add_gpu((1, 1, 1), (size // 2, 1, 1), (a_gpu, b_gpu, c_gpu, size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4a36373-1cef-4e38-9d64-30e7a714a60b",
      "metadata": {
        "id": "e4a36373-1cef-4e38-9d64-30e7a714a60b"
      },
      "outputs": [],
      "source": [
        "# size of the vectors\n",
        "size = 2048\n",
        "\n",
        "# allocating and populating the vectors\n",
        "a_gpu = cupy.random.rand(size, dtype=cupy.float32)\n",
        "b_gpu = cupy.random.rand(size, dtype=cupy.float32)\n",
        "c_gpu = cupy.zeros(size, dtype=cupy.float32)\n",
        "a_cpu = cupy.asnumpy(a_gpu)\n",
        "b_cpu = cupy.asnumpy(b_gpu)\n",
        "c_cpu = np.zeros(size, dtype=np.float32)\n",
        "\n",
        "# CPU code\n",
        "def vector_add(A, B, C, size):\n",
        "    for item in range(0, size):\n",
        "        C[item] = A[item] + B[item]\n",
        "\n",
        "# CUDA vector_add\n",
        "vector_add_gpu = cupy.RawKernel(r'''\n",
        "extern \"C\"\n",
        "__global__ void vector_add(const float * A, const float * B, float * C, const int size)\n",
        "{\n",
        "    int item = threadIdx.x;\n",
        "    C[item] = A[item] + B[item];\n",
        "}\n",
        "''', \"vector_add\")\n",
        "\n",
        "# execute the code\n",
        "vector_add_gpu((2, 1, 1), (size // 2, 1, 1), (a_gpu, b_gpu, c_gpu, size))\n",
        "vector_add(a_cpu, b_cpu, c_cpu, size)\n",
        "\n",
        "# test\n",
        "if np.allclose(c_cpu, c_gpu):\n",
        "    print(\"Correct results!\")\n",
        "else:\n",
        "    print(\"Wrong results!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a75cd99-c2de-4c56-ac3d-6a805bd6be22",
      "metadata": {
        "id": "8a75cd99-c2de-4c56-ac3d-6a805bd6be22"
      },
      "outputs": [],
      "source": [
        "# CUDA vector_add\n",
        "vector_add_gpu = cupy.RawKernel(r'''\n",
        "extern \"C\"\n",
        "__global__ void vector_add(const float * A, const float * B, float * C, const int size)\n",
        "{\n",
        "   int item = (blockIdx.x * blockDim.x) + threadIdx.x;\n",
        "   if ( item < size )\n",
        "   {\n",
        "      C[item] = A[item] + B[item];\n",
        "   }\n",
        "}\n",
        "''', \"vector_add\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43b5f8ed-f2c8-415b-a1f3-798e9a8c0333",
      "metadata": {
        "id": "43b5f8ed-f2c8-415b-a1f3-798e9a8c0333"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "grid_size = (int(math.ceil(size / 1024)), 1, 1)\n",
        "block_size = (1024, 1, 1)\n",
        "\n",
        "vector_add_gpu(grid_size, block_size, (a_gpu, b_gpu, c_gpu, size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3045483-7a90-4231-b7df-632a8e0e13c5",
      "metadata": {
        "id": "b3045483-7a90-4231-b7df-632a8e0e13c5"
      },
      "outputs": [],
      "source": [
        "threads_per_block = 1024\n",
        "grid_size = (int(math.ceil(size / threads_per_block)), 1, 1)\n",
        "block_size = (threads_per_block, 1, 1)\n",
        "\n",
        "vector_add_gpu(grid_size, block_size, (a_gpu, b_gpu, c_gpu, size))\n",
        "vector_add(a_cpu, b_cpu, c_cpu, size)\n",
        "\n",
        "# test\n",
        "if np.allclose(c_cpu, c_gpu):\n",
        "    print(\"Correct results!\")\n",
        "else:\n",
        "    print(\"Wrong results!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55631a99-47a4-4558-b6cf-b49b73fd53c8",
      "metadata": {
        "id": "55631a99-47a4-4558-b6cf-b49b73fd53c8"
      },
      "outputs": [],
      "source": [
        "c_cpu.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13507392-aaa0-4c8d-afca-8db705da38f7",
      "metadata": {
        "id": "13507392-aaa0-4c8d-afca-8db705da38f7"
      },
      "outputs": [],
      "source": [
        "c_gpu.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a615e1f3-7ca1-49a7-8b78-8680e389fb47",
      "metadata": {
        "id": "a615e1f3-7ca1-49a7-8b78-8680e389fb47"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cupy\n",
        "import math\n",
        "from cupyx.profiler import benchmark\n",
        "\n",
        "# CPU version\n",
        "def all_primes_to(upper : int, prime_list : list):\n",
        "    for num in range(0, upper):\n",
        "        prime = True\n",
        "        for i in range(2, (num // 2) + 1):\n",
        "            if (num % i) == 0:\n",
        "                prime = False\n",
        "                break\n",
        "        if prime:\n",
        "            prime_list[num] = 1\n",
        "\n",
        "upper_bound = 100_000\n",
        "all_primes_cpu = np.zeros(upper_bound, dtype=np.int32)\n",
        "\n",
        "# GPU version\n",
        "check_prime_gpu_code = r'''\n",
        "extern \"C\"\n",
        "__global__ void all_primes_to(int size, int * const all_prime_numbers)\n",
        "{\n",
        "   int item = (blockIdx.x * blockDim.x) + threadIdx.x;\n",
        "   int result = 1;\n",
        "   \n",
        "   if ( item < size )\n",
        "   {\n",
        "       for ( int factor = 2; factor <= item / 2; factor++ )\n",
        "       {\n",
        "           if ( item % factor == 0 )\n",
        "           {\n",
        "               result = 0;\n",
        "               break;\n",
        "           }\n",
        "       }\n",
        "\n",
        "       all_prime_numbers[item] = result;\n",
        "   }\n",
        "}\n",
        "'''\n",
        "# Allocate memory\n",
        "all_primes_gpu = cupy.zeros(upper_bound, dtype=cupy.int32)\n",
        "\n",
        "# Setup the grid\n",
        "all_primes_to_gpu = cupy.RawKernel(check_prime_gpu_code, \"all_primes_to\")\n",
        "grid_size = (int(math.ceil(upper_bound / 1024)), 1, 1)\n",
        "block_size = (1024, 1, 1)\n",
        "\n",
        "# Benchmark and test\n",
        "%timeit -n 1 -r 1 all_primes_to(upper_bound, all_primes_cpu)\n",
        "execution_gpu = benchmark(all_primes_to_gpu, (grid_size, block_size, (upper_bound, all_primes_gpu)), n_repeat=10)\n",
        "gpu_avg_time = np.average(execution_gpu.gpu_times)\n",
        "print(f\"{gpu_avg_time:.6f} s\")\n",
        "\n",
        "if np.allclose(all_primes_cpu, all_primes_gpu):\n",
        "    print(\"Correct results!\")\n",
        "else:\n",
        "    print(\"Wrong results!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7210b79d-d6f1-41d6-8457-3957c20ccb3c",
      "metadata": {
        "id": "7210b79d-d6f1-41d6-8457-3957c20ccb3c"
      },
      "outputs": [],
      "source": [
        "all_primes_cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5531885b-5bf9-480a-88f4-8912851c55e1",
      "metadata": {
        "id": "5531885b-5bf9-480a-88f4-8912851c55e1"
      },
      "outputs": [],
      "source": [
        "all_primes_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65743cbd-ed7e-48e8-9510-d9de6ac534e1",
      "metadata": {
        "id": "65743cbd-ed7e-48e8-9510-d9de6ac534e1"
      },
      "source": [
        "## Registers, Global, and Local Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83ef770f-f0f3-43fb-8f4f-ab5120afd351",
      "metadata": {
        "id": "83ef770f-f0f3-43fb-8f4f-ab5120afd351"
      },
      "source": [
        "## Shared Memory and Synchronization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7560c644-8302-4293-afed-ee64b5226b09",
      "metadata": {
        "id": "7560c644-8302-4293-afed-ee64b5226b09"
      },
      "outputs": [],
      "source": [
        "def histogram(input_array, output_array):\n",
        "    for item in input_array:\n",
        "        output_array[item] = output_array[item] + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e697d56-3953-44d8-b336-b5fa2600fb91",
      "metadata": {
        "id": "7e697d56-3953-44d8-b336-b5fa2600fb91"
      },
      "outputs": [],
      "source": [
        "input_array = np.random.randint(256, size=2048, dtype=np.int32)\n",
        "output_array = np.zeros(256, dtype=np.int32)\n",
        "histogram(input_array, output_array)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c5b7223-b6d2-4173-923c-1767dbb64f65",
      "metadata": {
        "id": "5c5b7223-b6d2-4173-923c-1767dbb64f65"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import cupy\n",
        "from cupyx.profiler import benchmark\n",
        "\n",
        "def histogram(input_array, output_array):\n",
        "    for item in input_array:\n",
        "        output_array[item] = output_array[item] + 1\n",
        "\n",
        "# input size\n",
        "size = 2**25\n",
        "\n",
        "# allocate memory on CPU and GPU\n",
        "input_gpu = cupy.random.randint(256, size=size, dtype=cupy.int32)\n",
        "input_cpu = cupy.asnumpy(input_gpu)\n",
        "output_gpu = cupy.zeros(256, dtype=cupy.int32)\n",
        "output_cpu = cupy.asnumpy(output_gpu)\n",
        "\n",
        "# CUDA code\n",
        "histogram_cuda_code = r'''\n",
        "extern \"C\"\n",
        "__global__ void histogram(const int * input, int * output)\n",
        "{\n",
        "    int item = (blockIdx.x * blockDim.x) + threadIdx.x;\n",
        "\n",
        "    atomicAdd(&(output[input[item]]), 1);\n",
        "}\n",
        "'''\n",
        "\n",
        "# compile and setup CUDA code\n",
        "histogram_gpu = cupy.RawKernel(histogram_cuda_code, \"histogram\")\n",
        "threads_per_block = 256\n",
        "grid_size = (int(math.ceil(size / threads_per_block)), 1, 1)\n",
        "block_size = (threads_per_block, 1, 1)\n",
        "\n",
        "# check correctness\n",
        "histogram(input_cpu, output_cpu)\n",
        "histogram_gpu(grid_size, block_size, (input_gpu, output_gpu))\n",
        "if np.allclose(output_cpu, output_gpu):\n",
        "    print(\"Correct results!\")\n",
        "else:\n",
        "    print(\"Wrong results!\")\n",
        "\n",
        "# measure performance\n",
        "%timeit -n 1 -r 1 histogram(input_cpu, output_cpu)\n",
        "execution_gpu = benchmark(histogram_gpu, (grid_size, block_size, (input_gpu, output_gpu)), n_repeat=10)\n",
        "gpu_avg_time = np.average(execution_gpu.gpu_times)\n",
        "print(f\"{gpu_avg_time:.6f} s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bee4c776-1d38-47f5-a836-d0ed6e70ae98",
      "metadata": {
        "id": "bee4c776-1d38-47f5-a836-d0ed6e70ae98"
      },
      "outputs": [],
      "source": [
        "# this will error\n",
        "# https://github.com/carpentries-incubator/lesson-gpu-programming/issues/97\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import cupy\n",
        "from cupyx.profiler import benchmark\n",
        "\n",
        "def histogram(input_array, output_array):\n",
        "    for item in input_array:\n",
        "        output_array[item] = output_array[item] + 1\n",
        "\n",
        "# input size\n",
        "size = 2**25\n",
        "\n",
        "# allocate memory on CPU and GPU\n",
        "input_gpu = cupy.random.randint(256, size=size, dtype=cupy.int32)\n",
        "input_cpu = cupy.asnumpy(input_gpu)\n",
        "output_gpu = cupy.zeros(256, dtype=cupy.int32)\n",
        "output_cpu = cupy.asnumpy(output_gpu)\n",
        "\n",
        "# CUDA code\n",
        "histogram_cuda_code = r'''\n",
        "__global__ void histogram(const int * input, int * output)\n",
        "{\n",
        "    int item = (blockIdx.x * blockDim.x) + threadIdx.x;\n",
        "    __shared__ int temp_histogram[256];\n",
        "    // Initialize shared memory and synchronize\n",
        "    temp_histogram[threadIdx.x] = 0;\n",
        " \n",
        "    // Compute shared memory histogram and synchronize\n",
        "    atomicAdd(&(temp_histogram[input[item]]), 1);\n",
        "\n",
        "    // Update global histogram\n",
        "    atomicAdd(&(output[threadIdx.x]), temp_histogram[threadIdx.x]);\n",
        "}\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "# compile and setup CUDA code\n",
        "histogram_gpu = cupy.RawKernel(histogram_cuda_code, \"histogram\")\n",
        "threads_per_block = 256\n",
        "grid_size = (int(math.ceil(size / threads_per_block)), 1, 1)\n",
        "block_size = (threads_per_block, 1, 1)\n",
        "\n",
        "# check correctness\n",
        "histogram(input_cpu, output_cpu)\n",
        "histogram_gpu(grid_size, block_size, (input_gpu, output_gpu))\n",
        "if np.allclose(output_cpu, output_gpu):\n",
        "    print(\"Correct results!\")\n",
        "else:\n",
        "    print(\"Wrong results!\")\n",
        "\n",
        "# measure performance\n",
        "%timeit -n 1 -r 1 histogram(input_cpu, output_cpu)\n",
        "execution_gpu = benchmark(histogram_gpu, (grid_size, block_size, (input_gpu, output_gpu)), n_repeat=10)\n",
        "gpu_avg_time = np.average(execution_gpu.gpu_times)\n",
        "print(f\"{gpu_avg_time:.6f} s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ca71761-2119-4820-b4d8-03b064f4f449",
      "metadata": {
        "id": "4ca71761-2119-4820-b4d8-03b064f4f449"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import cupy\n",
        "from cupyx.profiler import benchmark\n",
        "\n",
        "def histogram(input_array, output_array):\n",
        "    for item in input_array:\n",
        "        output_array[item] = output_array[item] + 1\n",
        "\n",
        "# input size\n",
        "size = 2**25\n",
        "\n",
        "# allocate memory on CPU and GPU\n",
        "input_gpu = cupy.random.randint(256, size=size, dtype=cupy.int32)\n",
        "input_cpu = cupy.asnumpy(input_gpu)\n",
        "output_gpu = cupy.zeros(256, dtype=cupy.int32)\n",
        "output_cpu = cupy.asnumpy(output_gpu)\n",
        "\n",
        "# CUDA code\n",
        "histogram_cuda_code = r'''\n",
        "extern \"C\"\n",
        "__global__ void histogram(const int * input, int * output)\n",
        "{\n",
        "    int item = (blockIdx.x * blockDim.x) + threadIdx.x;\n",
        "    __shared__ int temp_histogram[256];\n",
        " \n",
        "    // Initialize shared memory and synchronize\n",
        "    temp_histogram[threadIdx.x] = 0;\n",
        "    __syncthreads();\n",
        "\n",
        "    // Compute shared memory histogram and synchronize\n",
        "    atomicAdd(&(temp_histogram[input[item]]), 1);\n",
        "    __syncthreads();\n",
        "\n",
        "    // Update global histogram\n",
        "    atomicAdd(&(output[threadIdx.x]), temp_histogram[threadIdx.x]);\n",
        "}\n",
        "'''\n",
        "\n",
        "# compile and setup CUDA code\n",
        "histogram_gpu = cupy.RawKernel(histogram_cuda_code, \"histogram\")\n",
        "threads_per_block = 256\n",
        "grid_size = (int(math.ceil(size / threads_per_block)), 1, 1)\n",
        "block_size = (threads_per_block, 1, 1)\n",
        "\n",
        "# check correctness\n",
        "histogram(input_cpu, output_cpu)\n",
        "histogram_gpu(grid_size, block_size, (input_gpu, output_gpu))\n",
        "if np.allclose(output_cpu, output_gpu):\n",
        "    print(\"Correct results!\")\n",
        "else:\n",
        "    print(\"Wrong results!\")\n",
        "\n",
        "# measure performance\n",
        "%timeit -n 1 -r 1 histogram(input_cpu, output_cpu)\n",
        "execution_gpu = benchmark(histogram_gpu, (grid_size, block_size, (input_gpu, output_gpu)), n_repeat=10)\n",
        "gpu_avg_time = np.average(execution_gpu.gpu_times)\n",
        "print(f\"{gpu_avg_time:.6f} s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5747688-bb61-499a-9402-0cb33dd080bd",
      "metadata": {
        "id": "a5747688-bb61-499a-9402-0cb33dd080bd"
      },
      "source": [
        "## Constant Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6e61eda-3477-47ef-83aa-d41966d15fd3",
      "metadata": {
        "id": "a6e61eda-3477-47ef-83aa-d41966d15fd3"
      },
      "outputs": [],
      "source": [
        "cuda_code = r'''\n",
        "extern \"C\" {\n",
        "#define BLOCKS 2\n",
        "\n",
        "__constant__ float factors[BLOCKS];\n",
        "\n",
        "__global__ void sum_and_multiply(const float * A, const float * B, float * C, const int size)\n",
        "{\n",
        "    int item = (blockIdx.x * blockDim.x) + threadIdx.x;\n",
        "    C[item] = (A[item] + B[item]) * factors[blockIdx.x];\n",
        "}\n",
        "}\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e67f5339-0e89-4e01-b4d3-235231c8f390",
      "metadata": {
        "id": "e67f5339-0e89-4e01-b4d3-235231c8f390"
      },
      "outputs": [],
      "source": [
        "# compile the code\n",
        "module = cupy.RawModule(code=cuda_code)\n",
        "# allocate and copy constant memory\n",
        "factors_ptr = module.get_global(\"factors\")\n",
        "factors_gpu = cupy.ndarray(2, cupy.float32, factors_ptr)\n",
        "factors_gpu[...] = cupy.random.random(2, dtype=cupy.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d6141c-f586-4674-9a88-221266e3bdf6",
      "metadata": {
        "id": "f9d6141c-f586-4674-9a88-221266e3bdf6"
      },
      "outputs": [],
      "source": [
        "print(factors_gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9de13889-2dd7-45e2-95a5-5fcbd111aef9",
      "metadata": {
        "id": "9de13889-2dd7-45e2-95a5-5fcbd111aef9"
      },
      "outputs": [],
      "source": [
        "# size of the vectors\n",
        "size = 2048\n",
        "\n",
        "# allocating and populating the vectors\n",
        "a_gpu = cupy.random.rand(size, dtype=cupy.float32)\n",
        "b_gpu = cupy.random.rand(size, dtype=cupy.float32)\n",
        "c_gpu = cupy.zeros(size, dtype=cupy.float32)\n",
        "# prepare arguments\n",
        "args = (a_gpu, b_gpu, c_gpu, size)\n",
        "\n",
        "# CUDA code\n",
        "cuda_code = r'''\n",
        "extern \"C\" {\n",
        "#define BLOCKS 2\n",
        "\n",
        "__constant__ float factors[BLOCKS];\n",
        "\n",
        "__global__ void sum_and_multiply(const float * A, const float * B, float * C, const int size)\n",
        "{\n",
        "    int item = (blockIdx.x * blockDim.x) + threadIdx.x;\n",
        "    C[item] = (A[item] + B[item]) * factors[blockIdx.x];\n",
        "}\n",
        "}\n",
        "'''\n",
        "\n",
        "# compile and access the code\n",
        "module = cupy.RawModule(code=cuda_code)\n",
        "sum_and_multiply = module.get_function(\"sum_and_multiply\")\n",
        "# allocate and copy constant memory\n",
        "factors_ptr = module.get_global(\"factors\")\n",
        "factors_gpu = cupy.ndarray(2, cupy.float32, factors_ptr)\n",
        "factors_gpu[...] = cupy.random.random(2, dtype=cupy.float32)\n",
        "\n",
        "sum_and_multiply((2, 1, 1), (size // 2, 1, 1), args)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "360b08db-16e6-43cd-845e-c8682d6523ee",
      "metadata": {
        "id": "360b08db-16e6-43cd-845e-c8682d6523ee"
      },
      "outputs": [],
      "source": [
        "# size of the vectors\n",
        "size = 10**6\n",
        "\n",
        "# allocating and populating the vectors\n",
        "a_gpu = cupy.random.rand(size, dtype=cupy.float32)\n",
        "b_gpu = cupy.random.rand(size, dtype=cupy.float32)\n",
        "c_gpu = cupy.zeros(size, dtype=cupy.float32)\n",
        "# prepare arguments\n",
        "args = (a_gpu, b_gpu, c_gpu, size)\n",
        "\n",
        "# CUDA code\n",
        "cuda_code = r'''\n",
        "extern \"C\" {\n",
        "__constant__ float factors[BLOCKS];\n",
        "\n",
        "__global__ void sum_and_multiply(const float * A, const float * B, float * C, const int size)\n",
        "{\n",
        "    int item = (blockIdx.x * blockDim.x) + threadIdx.x;\n",
        "    if ( item < size )\n",
        "    {\n",
        "        C[item] = (A[item] + B[item]) * factors[blockIdx.x];\n",
        "    }\n",
        "}\n",
        "}\n",
        "'''\n",
        "\n",
        "# compute the number of blocks and replace \"BLOCKS\" in the CUDA code\n",
        "threads_per_block = 1024\n",
        "num_blocks = int(math.ceil(size / threads_per_block))\n",
        "cuda_code = cuda_code.replace(\"BLOCKS\", f\"{num_blocks}\") \n",
        "\n",
        "# compile and access the code\n",
        "module = cupy.RawModule(code=cuda_code)\n",
        "sum_and_multiply = module.get_function(\"sum_and_multiply\")\n",
        "# allocate and copy constant memory\n",
        "factors_ptr = module.get_global(\"factors\")\n",
        "factors_gpu = cupy.ndarray(num_blocks, cupy.float32, factors_ptr)\n",
        "factors_gpu[...] = cupy.random.random(num_blocks, dtype=cupy.float32)\n",
        "\n",
        "sum_and_multiply((num_blocks, 1, 1), (threads_per_block, 1, 1), args)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab685297-5f6f-4293-9beb-668159079705",
      "metadata": {
        "id": "ab685297-5f6f-4293-9beb-668159079705"
      },
      "source": [
        "## Concurrent access to the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3b99db4-880b-4a71-bb14-7308904888ca",
      "metadata": {
        "id": "f3b99db4-880b-4a71-bb14-7308904888ca"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cupy\n",
        "import math\n",
        "from cupyx.profiler import benchmark\n",
        "\n",
        "upper_bound = 100_000\n",
        "histogram_size = 2**25\n",
        "\n",
        "# GPU code\n",
        "check_prime_gpu_code = r'''\n",
        "extern \"C\"\n",
        "__global__ void all_primes_to(int size, int * const all_prime_numbers)\n",
        "{\n",
        "    int number = (blockIdx.x * blockDim.x) + threadIdx.x;\n",
        "    int result = 1;\n",
        "\n",
        "    if ( number < size )\n",
        "    {\n",
        "        for ( int factor = 2; factor <= number / 2; factor++ )\n",
        "        {\n",
        "            if ( number % factor == 0 )\n",
        "            {\n",
        "                result = 0;\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        all_prime_numbers[number] = result;\n",
        "    }\n",
        "}\n",
        "'''\n",
        "histogram_cuda_code = r'''\n",
        "extern \"C\"\n",
        "__global__ void histogram(const int * input, int * output)\n",
        "{\n",
        "    int item = (blockIdx.x * blockDim.x) + threadIdx.x;\n",
        "    __shared__ int temp_histogram[256];\n",
        " \n",
        "    // Initialize shared memory and synchronize\n",
        "    temp_histogram[threadIdx.x] = 0;\n",
        "    __syncthreads();\n",
        "\n",
        "    // Compute shared memory histogram and synchronize\n",
        "    atomicAdd(&(temp_histogram[input[item]]), 1);\n",
        "    __syncthreads();\n",
        "\n",
        "    // Update global histogram\n",
        "    atomicAdd(&(output[threadIdx.x]), temp_histogram[threadIdx.x]);\n",
        "}\n",
        "'''\n",
        "\n",
        "# Allocate memory\n",
        "all_primes_gpu = cupy.zeros(upper_bound, dtype=cupy.int32)\n",
        "input_gpu = cupy.random.randint(256, size=histogram_size, dtype=cupy.int32)\n",
        "output_gpu = cupy.zeros(256, dtype=cupy.int32)\n",
        "\n",
        "# Compile and setup the grid\n",
        "all_primes_to_gpu = cupy.RawKernel(check_prime_gpu_code, \"all_primes_to\")\n",
        "grid_size_primes = (int(math.ceil(upper_bound / 1024)), 1, 1)\n",
        "block_size_primes = (1024, 1, 1)\n",
        "histogram_gpu = cupy.RawKernel(histogram_cuda_code, \"histogram\")\n",
        "threads_per_block_hist = 256\n",
        "grid_size_hist = (int(math.ceil(histogram_size / threads_per_block_hist)), 1, 1)\n",
        "block_size_hist = (threads_per_block_hist, 1, 1)\n",
        "\n",
        "# Execute the kernels\n",
        "all_primes_to_gpu(grid_size_primes, block_size_primes, (upper_bound, all_primes_gpu))\n",
        "histogram_gpu(grid_size_hist, block_size_hist, (input_gpu, output_gpu))\n",
        "\n",
        "# Save results\n",
        "output_one = all_primes_gpu\n",
        "output_two = output_gpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b77e2d89-2a7d-45e5-a4f3-48435eeca511",
      "metadata": {
        "id": "b77e2d89-2a7d-45e5-a4f3-48435eeca511"
      },
      "outputs": [],
      "source": [
        "stream_one = cupy.cuda.Stream()\n",
        "stream_two = cupy.cuda.Stream()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066b9cbd-9a98-432d-b335-1c8c75431f8e",
      "metadata": {
        "id": "066b9cbd-9a98-432d-b335-1c8c75431f8e"
      },
      "outputs": [],
      "source": [
        "with stream_one:\n",
        "    all_primes_to_gpu(grid_size_primes, block_size_primes, (upper_bound, all_primes_gpu))\n",
        "with stream_two:\n",
        "    histogram_gpu(grid_size_hist, block_size_hist, (input_gpu, output_gpu))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2cbc794-e804-44cb-aa3f-a6b3f777b554",
      "metadata": {
        "id": "c2cbc794-e804-44cb-aa3f-a6b3f777b554"
      },
      "outputs": [],
      "source": [
        "stream_one.synchronize()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "425bf94f-aadb-41ce-badf-c88ee8afcfb5",
      "metadata": {
        "id": "425bf94f-aadb-41ce-badf-c88ee8afcfb5"
      },
      "outputs": [],
      "source": [
        "interesting_event = cupy.cuda.Event()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc77791b-7296-4c5b-b0bf-4ef50dee9312",
      "metadata": {
        "id": "bc77791b-7296-4c5b-b0bf-4ef50dee9312"
      },
      "outputs": [],
      "source": [
        "stream_one = cupy.cuda.Stream()\n",
        "stream_two = cupy.cuda.Stream()\n",
        "sync_point = cupy.cuda.Event()\n",
        "\n",
        "with stream_one:\n",
        "    all_primes_to_gpu(grid_size_primes, block_size_primes, (upper_bound, all_primes_gpu))\n",
        "    sync_point.record(stream=stream_one)\n",
        "    all_primes_to_gpu(grid_size_primes, block_size_primes, (upper_bound, all_primes_gpu))\n",
        "with stream_two:\n",
        "    stream_two.wait_event(sync_point)\n",
        "    histogram_gpu(grid_size_hist, block_size_hist, (input_gpu, output_gpu))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d441b14b-c23d-4db9-8b85-196f6f6cea97",
      "metadata": {
        "id": "d441b14b-c23d-4db9-8b85-196f6f6cea97"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import cupy\n",
        "import numpy as np\n",
        "\n",
        "# size of the vectors\n",
        "size = 100_000_000\n",
        "\n",
        "# allocating and populating the vectors\n",
        "a_gpu = cupy.random.rand(size, dtype=cupy.float32)\n",
        "b_gpu = cupy.random.rand(size, dtype=cupy.float32)\n",
        "c_gpu = cupy.zeros(size, dtype=cupy.float32)\n",
        "a_cpu = cupy.asnumpy(a_gpu)\n",
        "b_cpu = cupy.asnumpy(b_gpu)\n",
        "c_cpu = np.zeros(size, dtype=np.float32)\n",
        "\n",
        "# CPU code\n",
        "def vector_add(A, B, C, size):\n",
        "    for item in range(0, size):\n",
        "        C[item] = A[item] + B[item]\n",
        "\n",
        "# CUDA vector_add\n",
        "vector_add_gpu = cupy.RawKernel(r'''\n",
        "extern \"C\"\n",
        "__global__ void vector_add(const float * A, const float * B, float * C, const int size)\n",
        "{\n",
        "   int item = (blockIdx.x * blockDim.x) + threadIdx.x;\n",
        "   if ( item < size )\n",
        "   {\n",
        "      C[item] = A[item] + B[item];\n",
        "   }\n",
        "}\n",
        "''', \"vector_add\")\n",
        "\n",
        "# execute the code and measure time\n",
        "threads_per_block = 1024\n",
        "grid_size = (int(math.ceil(size / threads_per_block)), 1, 1)\n",
        "block_size = (threads_per_block, 1, 1)\n",
        "%timeit -n 1 -r 1 vector_add(a_cpu, b_cpu, c_cpu, size)\n",
        "gpu_times = []\n",
        "for _ in range(0, 10):\n",
        "    start_gpu = cupy.cuda.Event()\n",
        "    end_gpu = cupy.cuda.Event()\n",
        "    start_gpu.record()\n",
        "    vector_add_gpu(grid_size, block_size, (a_gpu, b_gpu, c_gpu, size))\n",
        "    end_gpu.record()\n",
        "    end_gpu.synchronize()\n",
        "    gpu_times.append(cupy.cuda.get_elapsed_time(start_gpu, end_gpu))\n",
        "gpu_avg_time = np.average(gpu_times)\n",
        "print(f\"{gpu_avg_time:.6f} s\")\n",
        "\n",
        "# test\n",
        "if np.allclose(c_cpu, c_gpu):\n",
        "    print(\"Correct results!\")\n",
        "else:\n",
        "    print(\"Wrong results!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}